{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "okFwIvZvKEb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-by-Step Guide to Setting Up Federated Learning with TensorFlow Federated:\n",
        "1. Install TensorFlow Federated\n",
        "\n",
        "You first need to install the tensorflow-federated library.\n",
        "\n",
        "In Google Colab, or your local Python environment, run:"
      ],
      "metadata": {
        "id": "pVKG_jkpKNHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow\n"
      ],
      "metadata": {
        "id": "gYdyfsfCTaxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.14.0\n"
      ],
      "metadata": {
        "id": "MHgxF-DPTe_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWBmERLTUexu",
        "outputId": "8b926c24-8774-423c-92a2-f3a12647ddbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_federated as tff\n",
        "\n",
        "# Check TensorFlow Federated version\n",
        "print(f\"TensorFlow Federated Version: {tff.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XRp8EtlUpjO",
        "outputId": "313678f7-2fcc-4982-f976-07f37fdfbc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Federated Version: 0.86.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Simulate client data\n",
        "def create_client_data():\n",
        "    \"\"\"Simulate simple datasets for each client.\"\"\"\n",
        "    return [\n",
        "        {\n",
        "            \"features\": np.random.rand(10, 5),  # 10 samples, 5 features each\n",
        "            \"labels\": np.random.randint(2, size=(10,))  # Binary classification (0 or 1)\n",
        "        } for _ in range(3)\n",
        "    ]\n",
        "\n",
        "client_data = create_client_data()\n",
        "\n",
        "# Step 2: Convert data to a TFF dataset\n",
        "def create_tf_dataset_for_client(data):\n",
        "    \"\"\"Convert client data into TensorFlow datasets.\"\"\"\n",
        "    return tf.data.Dataset.from_tensor_slices((data[\"features\"], data[\"labels\"])).batch(2)\n",
        "\n",
        "federated_train_data = [create_tf_dataset_for_client(client) for client in client_data]\n",
        "\n",
        "# Step 3: Define a model using Keras\n",
        "def model_fn():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(5,)),  # 5 features\n",
        "        tf.keras.layers.Dense(10, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    # Use tff.learning.models.Model to wrap the Keras model\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=model,\n",
        "        input_spec=federated_train_data[0].element_spec,\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n",
        "\n",
        "# Step 4: Build the federated learning process using the updated API\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
        ")\n",
        "\n",
        "# Step 5: Initialize the federated learning process\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "# Step 6: Run a few rounds of federated learning\n",
        "for round_num in range(1, 11):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    print(f'Round {round_num}, metrics={metrics}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dLbDuJZ4W_Yz",
        "outputId": "3ce67931-94f2-4c60-cbf6-1d8ec94677bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.4), ('loss', 0.7357788), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.46666667), ('loss', 0.7263995), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.46666667), ('loss', 0.7179159), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.5), ('loss', 0.7114427), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.43333334), ('loss', 0.70483017), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.46666667), ('loss', 0.69937474), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.53333336), ('loss', 0.6945999), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.46666667), ('loss', 0.6903745), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.46666667), ('loss', 0.686573), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.46666667), ('loss', 0.6831255), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increase the Number of Rounds: You can train the model for more rounds to see further improvement in performance."
      ],
      "metadata": {
        "id": "PvPZdYDwX6_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for round_num in range(11, 21):  # Continue for 10 more rounds\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    print(f'Round {round_num}, metrics={metrics}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRuvz1CjX8lL",
        "outputId": "5953c60f-6046-45d5-bf26-87cf9bce0e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 11, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.53333336), ('loss', 0.6800981), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 12, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.53333336), ('loss', 0.6775046), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 13, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.56666666), ('loss', 0.67537344), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 14, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.56666666), ('loss', 0.6730592), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 15, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.56666666), ('loss', 0.6705525), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 16, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.6), ('loss', 0.66828996), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 17, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.6), ('loss', 0.66645634), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 18, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.6), ('loss', 0.6652994), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 19, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.6333333), ('loss', 0.66407746), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 20, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.6333333), ('loss', 0.66306305), ('num_examples', 30), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhance the Model Architecture"
      ],
      "metadata": {
        "id": "hckkDBx0YKyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enhanced_model_fn():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(5,)),  # 5 features\n",
        "        tf.keras.layers.Dense(64, activation='relu'),  # Increased neurons\n",
        "        tf.keras.layers.Dense(32, activation='relu'),  # Additional dense layer\n",
        "        tf.keras.layers.Dense(16, activation='relu'),  # Additional dense layer\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=model,\n",
        "        input_spec=federated_train_data[0].element_spec,\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "_9dOptziYOLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Adjust the Learning Rate\n",
        "\n",
        " -  A higher learning rate can speed up convergence but might cause the model to miss optimal points.\n",
        " - A lower learning rate can slow down training but often leads to better convergence and performance.\n",
        "\n",
        "Experimenting with different learning rates for both clients and the server can help improve accuracy. Here's an example where we adjust the learning rates:"
      ],
      "metadata": {
        "id": "e2rD7mG1Ymst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusted learning rates for clients and server\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=enhanced_model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),  # Lower learning rate\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.5)  # Adjusted server learning rate\n",
        ")\n"
      ],
      "metadata": {
        "id": "G2KtJ6MXYqEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Try a Different Optimizer\n",
        "\n",
        "    - You can experiment with different optimizers like Adam, RMSprop, or Adagrad instead of SGD. These optimizers adapt their learning rates during training, which can improve convergence.\n",
        "\n",
        "Example using Adam optimizer:"
      ],
      "metadata": {
        "id": "Kl1Cs3SDYzvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=enhanced_model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        ")\n"
      ],
      "metadata": {
        "id": "GK8_xVmrZFWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Increase the Number of Training Rounds\n",
        "\n",
        "Federated learning typically requires more rounds to achieve convergence, especially when each client has a limited dataset. You can run more training rounds to allow the model to learn better."
      ],
      "metadata": {
        "id": "ssziYAZ3ZLjm"
      }
    }
  ]
}